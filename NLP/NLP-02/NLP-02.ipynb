{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8ab10a",
   "metadata": {},
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3f81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md') # returns a Language class instance, nlp. This Language class is the text processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12697c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('I own a dell computer.') # doc is a Doc class instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efc5021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'own', 'a', 'ginger', 'cat', '.']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dd93e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"It's been a crazy week!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96d1cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', \"'s\", 'been', 'a', 'crazy', 'week', '!', '!', '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d9a9d",
   "metadata": {},
   "source": [
    "#### customizing the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dd08d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"gimme that book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3798f30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'that', 'book']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.text for w in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d87fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0627464",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_case = [{ORTH: \"gim\"}, {ORTH: \"me\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a371dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer.add_special_case(\"gimme\", special_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03e73596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'that', 'book']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.text for w in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75234b2",
   "metadata": {},
   "source": [
    "#### Debugging the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a2f66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"let's go!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "761c5bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4817244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_exp = nlp.tokenizer.explain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "587354f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let \t SPECIAL-1\n",
      "'s \t SPECIAL-2\n",
      "go \t TOKEN\n",
      "! \t SUFFIX\n"
     ]
    }
   ],
   "source": [
    "for t in tok_exp:\n",
    "    print(t[1], '\\t', t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e986f38",
   "metadata": {},
   "source": [
    "#### Sentence segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "333f8842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "I flew to Melbourne yesterday.\n",
      "***\n",
      "I was at my hotel at 5 pm.\n"
     ]
    }
   ],
   "source": [
    "text = \"I flew to Melbourne yesterday. I was at my hotel at 5 pm.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    print(\"***\")\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298971c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
