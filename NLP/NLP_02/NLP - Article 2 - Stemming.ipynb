{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attempted-session",
   "metadata": {},
   "source": [
    "## Word Stemming\n",
    "#### Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "identical-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gentle-advantage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('walk', 'walk', 'walk')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps.stem('walking'), ps.stem('walked'), ps.stem('walks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-springfield",
   "metadata": {},
   "source": [
    "#### Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "micro-click",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('walk', 'walk', 'walk')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "ls = LancasterStemmer()\n",
    "ls.stem('walking'), ls.stem('walked'), ls.stem('walks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-spelling",
   "metadata": {},
   "source": [
    "#### Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "automated-state",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('walk', 'walk', 'walk')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "ss = LancasterStemmer()\n",
    "ss.stem('walking'), ss.stem('walked'), ss.stem('walks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-substitute",
   "metadata": {},
   "source": [
    "## Sentence Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acute-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handy-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"These Guidelines have been developed for use in the fire engineering design and \n",
    "approval of buildings.  \"\"\"\n",
    "def sentenceStemmer(sentence):\n",
    "    # tokenize the sentence\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    # empty list\n",
    "    stem_sentence = []\n",
    "    for word in word_tokens:\n",
    "        # append stemmed word to the empty list\n",
    "        stem_sentence.append(ps.stem(word))\n",
    "    # join the list items to form a sentence\n",
    "    return \" \".join(stem_sentence)\n",
    "x = sentenceStemmer(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "capital-brush",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'these guidelin have been develop for use in the fire engin design and approv of build .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-mount",
   "metadata": {},
   "source": [
    "## Paragraph Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "attractive-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"These Guidelines have been developed for use in the fire engineering design and \n",
    "approval of buildings. However, the concepts and principles may also be of assistance in \n",
    "the fire engineering design and approval of other structures such as ships and tunnels \n",
    "which comprise of enclosed spaces.  \"\"\"\n",
    "# remove the linebreaks at the end of the line\n",
    "paragraph = paragraph.replace('\\n',\"\")\n",
    "# tokenize the paragraph into a list of sentences\n",
    "sentences = sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "infrared-tampa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['These Guidelines have been developed for use in the fire engineering design and approval of buildings.',\n",
       " 'However, the concepts and principles may also be of assistance in the fire engineering design and approval of other structures such as ships and tunnels which comprise of enclosed spaces.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "recent-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceStemmer(sentence):\n",
    "    # tokenize sentence to words\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    # empty list\n",
    "    stem_sentence = []\n",
    "    for word in word_tokens:\n",
    "        # append stemmed words to empty list\n",
    "        stem_sentence.append(ps.stem(word))\n",
    "    return \" \".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "integral-australian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['these guidelin have been develop for use in the fire engin design and approv of build .',\n",
       " 'howev , the concept and principl may also be of assist in the fire engin design and approv of other structur such as ship and tunnel which compris of enclos space .']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_sentence = []\n",
    "for sentence in sentences:\n",
    "    stem_sentence.append(sentenceStemmer(sentence))\n",
    "stem_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-label",
   "metadata": {},
   "source": [
    "## Document Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "strange-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "removed-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\AUJV501965\\OneDrive\\JabirJamal.com\\NLP\\NLP_02_Lemmatization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thousand-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open text file located in the folder \n",
    "file = open('document.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "demonstrated-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lines in the file\n",
    "\n",
    "lines = file.readlines()\n",
    "updated_lines=[]\n",
    "for line in lines:\n",
    "    # remove linebreaks\n",
    "    line = line.replace('\\n',\"\")\n",
    "    updated_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "opening-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceStemmer(sentence):\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    stem_sentence = []\n",
    "    for word in word_tokens:\n",
    "        stem_sentence.append(ps.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lesser-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file to write data\n",
    "stem_file = open('stem_document.txt', mode=\"w+\", encoding = 'utf-8')\n",
    "for line in updated_lines:\n",
    "    stem_sentence = sentenceStemmer(line)\n",
    "    # write data\n",
    "    stem_file.write(stem_sentence)\n",
    "\n",
    "# close file\n",
    "stem_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-summary",
   "metadata": {},
   "source": [
    "## List comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sustained-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehension \n",
    "def sentenceStemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stem_words = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return stem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-observation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
